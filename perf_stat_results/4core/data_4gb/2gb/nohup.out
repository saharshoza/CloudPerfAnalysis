========== running Terasort benchmark ==========
Terasort opt hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output 
sh -c  /usr/local/spark/bin/spark-submit --class src.main.scala.terasortApp --master spark://10.40.0.230:7077 --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=hdfs://10.40.0.230:9000/eventLogging --driver-memory 2g   --conf spark.storage.memoryFraction=0.48 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.rdd.compress=false --conf spark.io.compression.codec=lzf  --jars /home/cc/spark-bench/Terasort/target/jars/guava-19.0-rc2.jar /home/cc/spark-bench/Terasort/target/TerasortApp-1.0-jar-with-dependencies.jar hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output  2>&1|tee /home/cc/spark-bench/bin/..//num/Terasort_run_2016-11-30-20:22:21.dat
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/11/30 20:22:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/11/30 20:22:22 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
16/11/30 20:22:23 INFO Slf4jLogger: Slf4jLogger started
16/11/30 20:22:23 INFO Remoting: Starting remoting
16/11/30 20:22:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.40.0.230:37143]
16/11/30 20:22:25 INFO FileInputFormat: Total input paths to process : 10
[Stage 0:>                                                         (0 + 0) / 30][Stage 0:>                                                         (0 + 4) / 30][Stage 0:===>                                                      (2 + 4) / 30][Stage 0:=====>                                                    (3 + 4) / 30][Stage 0:=======>                                                  (4 + 4) / 30][Stage 0:===========>                                              (6 + 5) / 30][Stage 0:=============>                                            (7 + 4) / 30][Stage 0:===============>                                          (8 + 4) / 30][Stage 0:===================>                                     (10 + 4) / 30][Stage 0:====================>                                    (11 + 4) / 30][Stage 0:======================>                                  (12 + 4) / 30][Stage 0:==========================>                              (14 + 4) / 30][Stage 0:============================>                            (15 + 4) / 30][Stage 0:==============================>                          (16 + 4) / 30][Stage 0:==================================>                      (18 + 4) / 30][Stage 0:====================================>                    (19 + 4) / 30][Stage 0:======================================>                  (20 + 4) / 30][Stage 0:=======================================>                 (21 + 4) / 30][Stage 0:=========================================>               (22 + 4) / 30][Stage 0:===========================================>             (23 + 4) / 30][Stage 0:=============================================>           (24 + 4) / 30][Stage 0:===============================================>         (25 + 4) / 30][Stage 0:=================================================>       (26 + 4) / 30][Stage 0:===================================================>     (27 + 3) / 30][Stage 0:=====================================================>   (28 + 2) / 30][Stage 0:=======================================================> (29 + 1) / 30][Stage 1:>                                                         (0 + 4) / 30][Stage 1:=======>                                                  (4 + 4) / 30][Stage 1:===========>                                              (6 + 5) / 30][Stage 1:===============>                                          (8 + 4) / 30][Stage 1:====================>                                    (11 + 4) / 30][Stage 1:======================>                                  (12 + 4) / 30][Stage 1:============================>                            (15 + 4) / 30][Stage 1:==============================>                          (16 + 4) / 30][Stage 1:==================================>                      (18 + 4) / 30][Stage 1:====================================>                    (19 + 4) / 30][Stage 1:=========================================>               (22 + 4) / 30][Stage 1:===========================================>             (23 + 4) / 30][Stage 1:===================================================>     (27 + 3) / 30][Stage 1:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:22:42 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[Stage 3:>                                                         (0 + 4) / 30][Stage 3:=>                                                        (1 + 4) / 30][Stage 3:=======>                                                  (4 + 4) / 30][Stage 3:=============>                                            (7 + 4) / 30][Stage 3:===============>                                          (8 + 4) / 30][Stage 3:=================>                                        (9 + 4) / 30][Stage 3:===================>                                     (10 + 4) / 30][Stage 3:====================>                                    (11 + 4) / 30][Stage 3:======================>                                  (12 + 4) / 30][Stage 3:==========================>                              (14 + 4) / 30][Stage 3:==============================>                          (16 + 4) / 30][Stage 3:==================================>                      (18 + 4) / 30][Stage 3:====================================>                    (19 + 4) / 30][Stage 3:======================================>                  (20 + 4) / 30][Stage 3:=========================================>               (22 + 4) / 30][Stage 3:===========================================>             (23 + 4) / 30][Stage 3:=============================================>           (24 + 4) / 30][Stage 3:===============================================>         (25 + 4) / 30][Stage 3:=================================================>       (26 + 4) / 30][Stage 3:===================================================>     (27 + 3) / 30][Stage 3:=====================================================>   (28 + 2) / 30][Stage 3:=======================================================> (29 + 1) / 30][Stage 4:>                                                         (0 + 4) / 30][Stage 4:=>                                                        (1 + 6) / 30][Stage 4:=====>                                                    (3 + 4) / 30][Stage 4:=======>                                                  (4 + 4) / 30][Stage 4:=========>                                                (5 + 4) / 30][Stage 4:===========>                                              (6 + 4) / 30][Stage 4:=============>                                            (7 + 4) / 30][Stage 4:===============>                                          (8 + 4) / 30][Stage 4:=================>                                        (9 + 4) / 30][Stage 4:====================>                                    (11 + 4) / 30][Stage 4:======================>                                  (12 + 4) / 30][Stage 4:========================>                                (13 + 4) / 30][Stage 4:==========================>                              (14 + 4) / 30][Stage 4:============================>                            (15 + 4) / 30][Stage 4:================================>                        (17 + 4) / 30][Stage 4:==================================>                      (18 + 4) / 30][Stage 4:====================================>                    (19 + 4) / 30][Stage 4:=========================================>               (22 + 4) / 30][Stage 4:===========================================>             (23 + 4) / 30][Stage 4:===========================================>             (23 + 5) / 30][Stage 4:=============================================>           (24 + 4) / 30][Stage 4:===============================================>         (25 + 4) / 30][Stage 4:=================================================>       (26 + 4) / 30][Stage 4:===================================================>     (27 + 3) / 30][Stage 4:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:24:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/11/30 20:24:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/11/30 20:24:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
========== running Terasort benchmark ==========
Terasort opt hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output 
rmr: DEPRECATED: Please use 'rm -r' instead.
16/11/30 20:24:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted hdfs://10.40.0.230:9000/SparkBench/Terasort/Output
sh -c  /usr/local/spark/bin/spark-submit --class src.main.scala.terasortApp --master spark://10.40.0.230:7077 --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=hdfs://10.40.0.230:9000/eventLogging --driver-memory 2g   --conf spark.storage.memoryFraction=0.48 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.rdd.compress=false --conf spark.io.compression.codec=lzf  --jars /home/cc/spark-bench/Terasort/target/jars/guava-19.0-rc2.jar /home/cc/spark-bench/Terasort/target/TerasortApp-1.0-jar-with-dependencies.jar hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output  2>&1|tee /home/cc/spark-bench/bin/..//num/Terasort_run_2016-11-30-20:25:00.dat
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/11/30 20:25:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/11/30 20:25:02 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
16/11/30 20:25:02 INFO Slf4jLogger: Slf4jLogger started
16/11/30 20:25:03 INFO Remoting: Starting remoting
16/11/30 20:25:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.40.0.230:59412]
16/11/30 20:25:05 INFO FileInputFormat: Total input paths to process : 10
[Stage 0:>                                                         (0 + 4) / 30][Stage 0:===>                                                      (2 + 4) / 30][Stage 0:=======>                                                  (4 + 4) / 30][Stage 0:=========>                                                (5 + 5) / 30][Stage 0:===============>                                          (8 + 4) / 30][Stage 0:=================>                                        (9 + 4) / 30][Stage 0:====================>                                    (11 + 4) / 30][Stage 0:======================>                                  (12 + 4) / 30][Stage 0:============================>                            (15 + 4) / 30][Stage 0:==============================>                          (16 + 4) / 30][Stage 0:====================================>                    (19 + 4) / 30][Stage 0:======================================>                  (20 + 4) / 30][Stage 0:=======================================>                 (21 + 4) / 30][Stage 0:===========================================>             (23 + 4) / 30][Stage 0:=============================================>           (24 + 4) / 30][Stage 0:=================================================>       (26 + 4) / 30][Stage 0:===================================================>     (27 + 3) / 30][Stage 0:=====================================================>   (28 + 2) / 30][Stage 1:>                                                         (0 + 0) / 30][Stage 1:=======>                                                  (4 + 4) / 30][Stage 1:===========>                                              (6 + 4) / 30][Stage 1:===============>                                          (8 + 4) / 30][Stage 1:====================>                                    (11 + 4) / 30][Stage 1:======================>                                  (12 + 4) / 30][Stage 1:========================>                                (13 + 4) / 30][Stage 1:==============================>                          (16 + 4) / 30][Stage 1:======================================>                  (20 + 4) / 30][Stage 1:=======================================>                 (21 + 4) / 30][Stage 1:=============================================>           (24 + 4) / 30][Stage 1:===============================================>         (25 + 4) / 30][Stage 1:=====================================================>   (28 + 2) / 30]                                                                                16/11/30 20:25:24 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[Stage 3:>                                                         (0 + 4) / 30][Stage 3:=>                                                        (1 + 4) / 30][Stage 3:=======>                                                  (4 + 4) / 30][Stage 3:=========>                                                (5 + 5) / 30][Stage 3:===============>                                          (8 + 4) / 30][Stage 3:=================>                                        (9 + 4) / 30][Stage 3:======================>                                  (12 + 4) / 30][Stage 3:============================>                            (15 + 4) / 30][Stage 3:==============================>                          (16 + 4) / 30][Stage 3:====================================>                    (19 + 4) / 30][Stage 3:======================================>                  (20 + 4) / 30][Stage 3:=======================================>                 (21 + 4) / 30][Stage 3:=============================================>           (24 + 4) / 30][Stage 3:===============================================>         (25 + 4) / 30][Stage 3:=====================================================>   (28 + 2) / 30][Stage 3:=======================================================> (29 + 1) / 30][Stage 4:>                                                         (0 + 4) / 30][Stage 4:=====>                                                    (3 + 4) / 30][Stage 4:=======>                                                  (4 + 4) / 30][Stage 4:=========>                                                (5 + 4) / 30][Stage 4:===========>                                              (6 + 4) / 30][Stage 4:===============>                                          (8 + 4) / 30][Stage 4:=================>                                        (9 + 4) / 30][Stage 4:===================>                                     (10 + 4) / 30][Stage 4:====================>                                    (11 + 4) / 30][Stage 4:======================>                                  (12 + 4) / 30][Stage 4:========================>                                (13 + 4) / 30][Stage 4:==========================>                              (14 + 4) / 30][Stage 4:============================>                            (15 + 4) / 30][Stage 4:==============================>                          (16 + 4) / 30][Stage 4:================================>                        (17 + 4) / 30][Stage 4:==================================>                      (18 + 4) / 30][Stage 4:======================================>                  (20 + 4) / 30][Stage 4:=======================================>                 (21 + 4) / 30][Stage 4:=========================================>               (22 + 4) / 30][Stage 4:===========================================>             (23 + 4) / 30][Stage 4:=============================================>           (24 + 4) / 30][Stage 4:===============================================>         (25 + 4) / 30][Stage 4:=================================================>       (26 + 4) / 30][Stage 4:===================================================>     (27 + 3) / 30][Stage 4:=====================================================>   (28 + 2) / 30][Stage 4:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:27:43 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/11/30 20:27:43 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/11/30 20:27:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
perf_stat_metrics.sh: line 4: 137624 Terminated              ( bash perf_stat_sub.sh $perfMetric $Workerpid )
========== running Terasort benchmark ==========
Terasort opt hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output 
rmr: DEPRECATED: Please use 'rm -r' instead.
16/11/30 20:27:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted hdfs://10.40.0.230:9000/SparkBench/Terasort/Output
sh -c  /usr/local/spark/bin/spark-submit --class src.main.scala.terasortApp --master spark://10.40.0.230:7077 --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=hdfs://10.40.0.230:9000/eventLogging --driver-memory 2g   --conf spark.storage.memoryFraction=0.48 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.rdd.compress=false --conf spark.io.compression.codec=lzf  --jars /home/cc/spark-bench/Terasort/target/jars/guava-19.0-rc2.jar /home/cc/spark-bench/Terasort/target/TerasortApp-1.0-jar-with-dependencies.jar hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output  2>&1|tee /home/cc/spark-bench/bin/..//num/Terasort_run_2016-11-30-20:27:53.dat
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/11/30 20:27:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/11/30 20:27:55 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
16/11/30 20:27:55 INFO Slf4jLogger: Slf4jLogger started
16/11/30 20:27:55 INFO Remoting: Starting remoting
16/11/30 20:27:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.40.0.230:52362]
16/11/30 20:27:59 INFO FileInputFormat: Total input paths to process : 10
[Stage 0:>                                                         (0 + 4) / 30][Stage 0:=======>                                                  (4 + 4) / 30][Stage 0:===========>                                              (6 + 4) / 30][Stage 0:===============>                                          (8 + 4) / 30][Stage 0:===============>                                          (8 + 5) / 30][Stage 0:===================>                                     (10 + 4) / 30][Stage 0:====================>                                    (11 + 4) / 30][Stage 0:========================>                                (13 + 4) / 30][Stage 0:==========================>                              (14 + 4) / 30][Stage 0:============================>                            (15 + 5) / 30][Stage 0:================================>                        (17 + 4) / 30][Stage 0:==================================>                      (18 + 4) / 30][Stage 0:=======================================>                 (21 + 4) / 30][Stage 0:=========================================>               (22 + 4) / 30][Stage 0:===========================================>             (23 + 4) / 30][Stage 0:===============================================>         (25 + 4) / 30][Stage 0:=================================================>       (26 + 4) / 30][Stage 0:===================================================>     (27 + 3) / 30][Stage 1:>                                                         (0 + 4) / 30][Stage 1:=======>                                                  (4 + 4) / 30][Stage 1:===============>                                          (8 + 4) / 30][Stage 1:=================>                                        (9 + 4) / 30][Stage 1:======================>                                  (12 + 4) / 30][Stage 1:========================>                                (13 + 4) / 30][Stage 1:==============================>                          (16 + 4) / 30][Stage 1:======================================>                  (20 + 4) / 30][Stage 1:=======================================>                 (21 + 4) / 30][Stage 1:=============================================>           (24 + 4) / 30][Stage 1:===============================================>         (25 + 4) / 30][Stage 1:=====================================================>   (28 + 2) / 30][Stage 1:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:28:17 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[Stage 3:>                                                         (0 + 4) / 30][Stage 3:=======>                                                  (4 + 4) / 30][Stage 3:=========>                                                (5 + 4) / 30][Stage 3:===============>                                          (8 + 4) / 30][Stage 3:=================>                                        (9 + 4) / 30][Stage 3:====================>                                    (11 + 4) / 30][Stage 3:======================>                                  (12 + 4) / 30][Stage 3:========================>                                (13 + 4) / 30][Stage 3:============================>                            (15 + 4) / 30][Stage 3:==============================>                          (16 + 4) / 30][Stage 3:================================>                        (17 + 4) / 30][Stage 3:==================================>                      (18 + 4) / 30][Stage 3:======================================>                  (20 + 4) / 30][Stage 3:=======================================>                 (21 + 4) / 30][Stage 3:===========================================>             (23 + 4) / 30][Stage 3:=============================================>           (24 + 4) / 30][Stage 3:===============================================>         (25 + 4) / 30][Stage 3:=================================================>       (26 + 4) / 30][Stage 3:=====================================================>   (28 + 2) / 30][Stage 3:=======================================================> (29 + 1) / 30][Stage 4:>                                                         (0 + 0) / 30][Stage 4:>                                                         (0 + 4) / 30][Stage 4:>                                                         (0 + 5) / 30][Stage 4:=======>                                                  (4 + 4) / 30][Stage 4:=========>                                                (5 + 4) / 30][Stage 4:=============>                                            (7 + 4) / 30][Stage 4:===============>                                          (8 + 4) / 30][Stage 4:=================>                                        (9 + 4) / 30][Stage 4:====================>                                    (11 + 4) / 30][Stage 4:======================>                                  (12 + 4) / 30][Stage 4:========================>                                (13 + 4) / 30][Stage 4:==========================>                              (14 + 4) / 30][Stage 4:============================>                            (15 + 4) / 30][Stage 4:==============================>                          (16 + 4) / 30][Stage 4:================================>                        (17 + 4) / 30][Stage 4:====================================>                    (19 + 4) / 30][Stage 4:======================================>                  (20 + 4) / 30][Stage 4:=======================================>                 (21 + 4) / 30][Stage 4:=========================================>               (22 + 4) / 30][Stage 4:===========================================>             (23 + 4) / 30][Stage 4:=============================================>           (24 + 4) / 30][Stage 4:===============================================>         (25 + 4) / 30][Stage 4:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:30:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/11/30 20:30:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/11/30 20:30:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
perf_stat_metrics.sh: line 4: 139260 Terminated              ( bash perf_stat_sub.sh $perfMetric $Workerpid )
========== running Terasort benchmark ==========
Terasort opt hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output 
rmr: DEPRECATED: Please use 'rm -r' instead.
16/11/30 20:30:31 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted hdfs://10.40.0.230:9000/SparkBench/Terasort/Output
sh -c  /usr/local/spark/bin/spark-submit --class src.main.scala.terasortApp --master spark://10.40.0.230:7077 --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=hdfs://10.40.0.230:9000/eventLogging --driver-memory 2g   --conf spark.storage.memoryFraction=0.48 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.rdd.compress=false --conf spark.io.compression.codec=lzf  --jars /home/cc/spark-bench/Terasort/target/jars/guava-19.0-rc2.jar /home/cc/spark-bench/Terasort/target/TerasortApp-1.0-jar-with-dependencies.jar hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output  2>&1|tee /home/cc/spark-bench/bin/..//num/Terasort_run_2016-11-30-20:30:34.dat
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/11/30 20:30:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/11/30 20:30:36 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
16/11/30 20:30:37 INFO Slf4jLogger: Slf4jLogger started
16/11/30 20:30:37 INFO Remoting: Starting remoting
16/11/30 20:30:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.40.0.230:56788]
16/11/30 20:30:39 INFO FileInputFormat: Total input paths to process : 10
[Stage 0:>                                                         (0 + 4) / 30][Stage 0:=======>                                                  (4 + 4) / 30][Stage 0:===============>                                          (8 + 4) / 30][Stage 0:=================>                                        (9 + 4) / 30][Stage 0:====================>                                    (11 + 4) / 30][Stage 0:======================>                                  (12 + 4) / 30][Stage 0:==========================>                              (14 + 4) / 30][Stage 0:============================>                            (15 + 4) / 30][Stage 0:==============================>                          (16 + 4) / 30][Stage 0:==================================>                      (18 + 4) / 30][Stage 0:====================================>                    (19 + 4) / 30][Stage 0:======================================>                  (20 + 4) / 30][Stage 0:=======================================>                 (21 + 5) / 30][Stage 0:=========================================>               (22 + 4) / 30][Stage 0:===========================================>             (23 + 4) / 30][Stage 0:=============================================>           (24 + 4) / 30][Stage 0:=================================================>       (26 + 4) / 30][Stage 0:===================================================>     (27 + 3) / 30][Stage 0:=====================================================>   (28 + 2) / 30][Stage 1:=======>                                                  (4 + 4) / 30][Stage 1:=========>                                                (5 + 4) / 30][Stage 1:===============>                                          (8 + 4) / 30][Stage 1:=================>                                        (9 + 4) / 30][Stage 1:======================>                                  (12 + 4) / 30][Stage 1:==============================>                          (16 + 4) / 30][Stage 1:======================================>                  (20 + 4) / 30][Stage 1:=======================================>                 (21 + 4) / 30][Stage 1:=============================================>           (24 + 4) / 30][Stage 1:===============================================>         (25 + 4) / 30][Stage 1:=================================================>       (26 + 4) / 30][Stage 1:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:30:58 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[Stage 3:>                                                         (0 + 4) / 30][Stage 3:=======>                                                  (4 + 4) / 30][Stage 3:===========>                                              (6 + 4) / 30][Stage 3:===============>                                          (8 + 4) / 30][Stage 3:=================>                                        (9 + 4) / 30][Stage 3:====================>                                    (11 + 4) / 30][Stage 3:======================>                                  (12 + 4) / 30][Stage 3:========================>                                (13 + 4) / 30][Stage 3:============================>                            (15 + 4) / 30][Stage 3:==============================>                          (16 + 4) / 30][Stage 3:================================>                        (17 + 4) / 30][Stage 3:======================================>                  (20 + 4) / 30][Stage 3:=======================================>                 (21 + 4) / 30][Stage 3:===========================================>             (23 + 4) / 30][Stage 3:=============================================>           (24 + 4) / 30][Stage 3:===============================================>         (25 + 4) / 30][Stage 3:===================================================>     (27 + 3) / 30][Stage 3:=====================================================>   (28 + 2) / 30][Stage 3:=======================================================> (29 + 1) / 30][Stage 4:>                                                         (0 + 0) / 30][Stage 4:>                                                         (0 + 4) / 30][Stage 4:===>                                                      (2 + 4) / 30][Stage 4:=======>                                                  (4 + 4) / 30][Stage 4:=========>                                                (5 + 4) / 30][Stage 4:===========>                                              (6 + 4) / 30][Stage 4:===============>                                          (8 + 4) / 30][Stage 4:=================>                                        (9 + 4) / 30][Stage 4:===================>                                     (10 + 4) / 30][Stage 4:====================>                                    (11 + 4) / 30][Stage 4:======================>                                  (12 + 4) / 30][Stage 4:========================>                                (13 + 4) / 30][Stage 4:==========================>                              (14 + 4) / 30][Stage 4:============================>                            (15 + 4) / 30][Stage 4:==============================>                          (16 + 4) / 30][Stage 4:================================>                        (17 + 4) / 30][Stage 4:==================================>                      (18 + 4) / 30][Stage 4:====================================>                    (19 + 4) / 30][Stage 4:======================================>                  (20 + 4) / 30][Stage 4:=======================================>                 (21 + 4) / 30][Stage 4:===========================================>             (23 + 4) / 30][Stage 4:=============================================>           (24 + 4) / 30][Stage 4:===============================================>         (25 + 4) / 30][Stage 4:===================================================>     (27 + 3) / 30][Stage 4:=====================================================>   (28 + 2) / 30][Stage 4:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:33:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/11/30 20:33:06 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/11/30 20:33:06 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
perf_stat_metrics.sh: line 4: 141046 Terminated              ( bash perf_stat_sub.sh $perfMetric $Workerpid )
========== running Terasort benchmark ==========
Terasort opt hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output 
rmr: DEPRECATED: Please use 'rm -r' instead.
16/11/30 20:33:15 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted hdfs://10.40.0.230:9000/SparkBench/Terasort/Output
sh -c  /usr/local/spark/bin/spark-submit --class src.main.scala.terasortApp --master spark://10.40.0.230:7077 --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=hdfs://10.40.0.230:9000/eventLogging --driver-memory 2g   --conf spark.storage.memoryFraction=0.48 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.rdd.compress=false --conf spark.io.compression.codec=lzf  --jars /home/cc/spark-bench/Terasort/target/jars/guava-19.0-rc2.jar /home/cc/spark-bench/Terasort/target/TerasortApp-1.0-jar-with-dependencies.jar hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output  2>&1|tee /home/cc/spark-bench/bin/..//num/Terasort_run_2016-11-30-20:33:18.dat
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/11/30 20:33:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/11/30 20:33:20 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
16/11/30 20:33:20 INFO Slf4jLogger: Slf4jLogger started
16/11/30 20:33:20 INFO Remoting: Starting remoting
16/11/30 20:33:21 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.40.0.230:43877]
16/11/30 20:33:23 INFO FileInputFormat: Total input paths to process : 10
[Stage 0:>                                                         (0 + 0) / 30][Stage 0:>                                                         (0 + 4) / 30][Stage 0:=======>                                                  (4 + 4) / 30][Stage 0:===============>                                          (8 + 4) / 30][Stage 0:=================>                                        (9 + 4) / 30][Stage 0:======================>                                  (12 + 4) / 30][Stage 0:========================>                                (13 + 4) / 30][Stage 0:============================>                            (15 + 4) / 30][Stage 0:==============================>                          (16 + 4) / 30][Stage 0:====================================>                    (19 + 4) / 30][Stage 0:====================================>                    (19 + 5) / 30][Stage 0:======================================>                  (20 + 4) / 30][Stage 0:=======================================>                 (21 + 4) / 30][Stage 0:===========================================>             (23 + 4) / 30][Stage 0:=============================================>           (24 + 4) / 30][Stage 0:===============================================>         (25 + 4) / 30][Stage 0:===================================================>     (27 + 3) / 30][Stage 0:=====================================================>   (28 + 2) / 30][Stage 0:=======================================================> (29 + 1) / 30][Stage 1:>                                                         (0 + 5) / 30][Stage 1:=======>                                                  (4 + 4) / 30][Stage 1:=========>                                                (5 + 4) / 30][Stage 1:===============>                                          (8 + 4) / 30][Stage 1:===============>                                          (8 + 5) / 30][Stage 1:======================>                                  (12 + 4) / 30][Stage 1:==============================>                          (16 + 4) / 30][Stage 1:==============================>                          (16 + 5) / 30][Stage 1:======================================>                  (20 + 4) / 30][Stage 1:=============================================>           (24 + 4) / 30][Stage 1:===================================================>     (27 + 3) / 30][Stage 1:=====================================================>   (28 + 2) / 30]                                                                                16/11/30 20:33:41 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[Stage 3:>                                                         (0 + 4) / 30][Stage 3:=====>                                                    (3 + 4) / 30][Stage 3:=======>                                                  (4 + 4) / 30][Stage 3:=========>                                                (5 + 4) / 30][Stage 3:===============>                                          (8 + 4) / 30][Stage 3:=================>                                        (9 + 4) / 30][Stage 3:======================>                                  (12 + 4) / 30][Stage 3:========================>                                (13 + 4) / 30][Stage 3:============================>                            (15 + 4) / 30][Stage 3:==============================>                          (16 + 4) / 30][Stage 3:================================>                        (17 + 4) / 30][Stage 3:======================================>                  (20 + 4) / 30][Stage 3:=======================================>                 (21 + 4) / 30][Stage 3:===========================================>             (23 + 4) / 30][Stage 3:=============================================>           (24 + 4) / 30][Stage 3:===============================================>         (25 + 4) / 30][Stage 3:=====================================================>   (28 + 2) / 30][Stage 3:=======================================================> (29 + 1) / 30][Stage 4:>                                                         (0 + 4) / 30][Stage 4:=>                                                        (1 + 4) / 30][Stage 4:=====>                                                    (3 + 4) / 30][Stage 4:=======>                                                  (4 + 4) / 30][Stage 4:===========>                                              (6 + 4) / 30][Stage 4:===============>                                          (8 + 4) / 30][Stage 4:====================>                                    (11 + 4) / 30][Stage 4:======================>                                  (12 + 4) / 30][Stage 4:========================>                                (13 + 4) / 30][Stage 4:==========================>                              (14 + 4) / 30][Stage 4:==============================>                          (16 + 4) / 30][Stage 4:================================>                        (17 + 4) / 30][Stage 4:==================================>                      (18 + 4) / 30][Stage 4:======================================>                  (20 + 4) / 30][Stage 4:=======================================>                 (21 + 4) / 30][Stage 4:=========================================>               (22 + 4) / 30][Stage 4:===========================================>             (23 + 4) / 30][Stage 4:=============================================>           (24 + 4) / 30][Stage 4:===============================================>         (25 + 4) / 30][Stage 4:=================================================>       (26 + 4) / 30][Stage 4:=====================================================>   (28 + 2) / 30][Stage 4:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:35:45 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/11/30 20:35:45 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/11/30 20:35:45 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
perf_stat_metrics.sh: line 4: 142773 Terminated              ( bash perf_stat_sub.sh $perfMetric $Workerpid )
========== running Terasort benchmark ==========
Terasort opt hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output 
rmr: DEPRECATED: Please use 'rm -r' instead.
16/11/30 20:35:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted hdfs://10.40.0.230:9000/SparkBench/Terasort/Output
sh -c  /usr/local/spark/bin/spark-submit --class src.main.scala.terasortApp --master spark://10.40.0.230:7077 --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=hdfs://10.40.0.230:9000/eventLogging --driver-memory 2g   --conf spark.storage.memoryFraction=0.48 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.rdd.compress=false --conf spark.io.compression.codec=lzf  --jars /home/cc/spark-bench/Terasort/target/jars/guava-19.0-rc2.jar /home/cc/spark-bench/Terasort/target/TerasortApp-1.0-jar-with-dependencies.jar hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output  2>&1|tee /home/cc/spark-bench/bin/..//num/Terasort_run_2016-11-30-20:35:56.dat
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/11/30 20:35:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/11/30 20:35:59 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
16/11/30 20:36:00 INFO Slf4jLogger: Slf4jLogger started
16/11/30 20:36:00 INFO Remoting: Starting remoting
16/11/30 20:36:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.40.0.230:35791]
16/11/30 20:36:02 INFO FileInputFormat: Total input paths to process : 10
[Stage 0:>                                                         (0 + 0) / 30][Stage 0:>                                                         (0 + 4) / 30][Stage 0:=======>                                                  (4 + 4) / 30][Stage 0:=======>                                                  (4 + 5) / 30][Stage 0:===============>                                          (8 + 4) / 30][Stage 0:=================>                                        (9 + 4) / 30][Stage 0:======================>                                  (12 + 4) / 30][Stage 0:========================>                                (13 + 4) / 30][Stage 0:==============================>                          (16 + 4) / 30][Stage 0:==================================>                      (18 + 4) / 30][Stage 0:====================================>                    (19 + 4) / 30][Stage 0:=======================================>                 (21 + 4) / 30][Stage 0:=========================================>               (22 + 4) / 30][Stage 0:===========================================>             (23 + 5) / 30][Stage 0:=================================================>       (26 + 4) / 30][Stage 0:===================================================>     (27 + 3) / 30][Stage 1:===>                                                      (2 + 4) / 30][Stage 1:=======>                                                  (4 + 4) / 30][Stage 1:===============>                                          (8 + 4) / 30][Stage 1:=================>                                        (9 + 4) / 30][Stage 1:======================>                                  (12 + 4) / 30][Stage 1:============================>                            (15 + 4) / 30][Stage 1:==============================>                          (16 + 4) / 30][Stage 1:======================================>                  (20 + 4) / 30][Stage 1:=============================================>           (24 + 4) / 30][Stage 1:===================================================>     (27 + 3) / 30][Stage 1:=====================================================>   (28 + 2) / 30]                                                                                16/11/30 20:36:18 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[Stage 3:>                                                         (0 + 4) / 30][Stage 3:=======>                                                  (4 + 4) / 30][Stage 3:===============>                                          (8 + 4) / 30][Stage 3:=================>                                        (9 + 4) / 30][Stage 3:===================>                                     (10 + 4) / 30][Stage 3:======================>                                  (12 + 4) / 30][Stage 3:========================>                                (13 + 4) / 30][Stage 3:==========================>                              (14 + 4) / 30][Stage 3:==============================>                          (16 + 4) / 30][Stage 3:================================>                        (17 + 4) / 30][Stage 3:==================================>                      (18 + 4) / 30][Stage 3:======================================>                  (20 + 4) / 30][Stage 3:=======================================>                 (21 + 4) / 30][Stage 3:=========================================>               (22 + 4) / 30][Stage 3:=============================================>           (24 + 4) / 30][Stage 3:===============================================>         (25 + 4) / 30][Stage 3:=================================================>       (26 + 4) / 30][Stage 3:=====================================================>   (28 + 2) / 30][Stage 3:=======================================================> (29 + 1) / 30][Stage 4:>                                                         (0 + 4) / 30][Stage 4:=>                                                        (1 + 4) / 30][Stage 4:=====>                                                    (3 + 4) / 30][Stage 4:=======>                                                  (4 + 4) / 30][Stage 4:=========>                                                (5 + 4) / 30][Stage 4:===========>                                              (6 + 4) / 30][Stage 4:=============>                                            (7 + 4) / 30][Stage 4:===============>                                          (8 + 4) / 30][Stage 4:=================>                                        (9 + 4) / 30][Stage 4:====================>                                    (11 + 4) / 30][Stage 4:======================>                                  (12 + 4) / 30][Stage 4:========================>                                (13 + 4) / 30][Stage 4:========================>                                (13 + 5) / 30][Stage 4:==========================>                              (14 + 4) / 30][Stage 4:============================>                            (15 + 4) / 30][Stage 4:==============================>                          (16 + 4) / 30][Stage 4:================================>                        (17 + 4) / 30][Stage 4:==================================>                      (18 + 4) / 30][Stage 4:====================================>                    (19 + 4) / 30][Stage 4:======================================>                  (20 + 4) / 30][Stage 4:=======================================>                 (21 + 4) / 30][Stage 4:=========================================>               (22 + 4) / 30][Stage 4:===========================================>             (23 + 4) / 30][Stage 4:===============================================>         (25 + 4) / 30][Stage 4:=================================================>       (26 + 4) / 30][Stage 4:===================================================>     (27 + 3) / 30][Stage 4:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:38:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/11/30 20:38:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/11/30 20:38:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
perf_stat_metrics.sh: line 4: 144506 Terminated              ( bash perf_stat_sub.sh $perfMetric $Workerpid )
========== running Terasort benchmark ==========
Terasort opt hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output 
rmr: DEPRECATED: Please use 'rm -r' instead.
16/11/30 20:38:13 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted hdfs://10.40.0.230:9000/SparkBench/Terasort/Output
sh -c  /usr/local/spark/bin/spark-submit --class src.main.scala.terasortApp --master spark://10.40.0.230:7077 --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=hdfs://10.40.0.230:9000/eventLogging --driver-memory 2g   --conf spark.storage.memoryFraction=0.48 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.rdd.compress=false --conf spark.io.compression.codec=lzf  --jars /home/cc/spark-bench/Terasort/target/jars/guava-19.0-rc2.jar /home/cc/spark-bench/Terasort/target/TerasortApp-1.0-jar-with-dependencies.jar hdfs://10.40.0.230:9000/SparkBench/Terasort/Input hdfs://10.40.0.230:9000/SparkBench/Terasort/Output  2>&1|tee /home/cc/spark-bench/bin/..//num/Terasort_run_2016-11-30-20:38:17.dat
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/11/30 20:38:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/11/30 20:38:19 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
16/11/30 20:38:20 INFO Slf4jLogger: Slf4jLogger started
16/11/30 20:38:20 INFO Remoting: Starting remoting
16/11/30 20:38:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.40.0.230:43669]
16/11/30 20:38:23 INFO FileInputFormat: Total input paths to process : 10
[Stage 0:>                                                         (0 + 4) / 30][Stage 0:=====>                                                    (3 + 4) / 30][Stage 0:=======>                                                  (4 + 4) / 30][Stage 0:===============>                                          (8 + 4) / 30][Stage 0:=================>                                        (9 + 4) / 30][Stage 0:======================>                                  (12 + 4) / 30][Stage 0:==========================>                              (14 + 4) / 30][Stage 0:==============================>                          (16 + 4) / 30][Stage 0:==================================>                      (18 + 4) / 30][Stage 0:====================================>                    (19 + 4) / 30][Stage 0:======================================>                  (20 + 5) / 30][Stage 0:=========================================>               (22 + 4) / 30][Stage 0:===========================================>             (23 + 4) / 30][Stage 0:=============================================>           (24 + 5) / 30][Stage 0:=================================================>       (26 + 4) / 30][Stage 0:===================================================>     (27 + 3) / 30][Stage 0:=====================================================>   (28 + 2) / 30][Stage 1:=======>                                                  (4 + 4) / 30][Stage 1:=========>                                                (5 + 4) / 30][Stage 1:===============>                                          (8 + 4) / 30][Stage 1:=================>                                        (9 + 4) / 30][Stage 1:======================>                                  (12 + 4) / 30][Stage 1:========================>                                (13 + 4) / 30][Stage 1:==============================>                          (16 + 4) / 30][Stage 1:================================>                        (17 + 4) / 30][Stage 1:======================================>                  (20 + 4) / 30][Stage 1:=======================================>                 (21 + 4) / 30][Stage 1:=========================================>               (22 + 4) / 30][Stage 1:=============================================>           (24 + 4) / 30][Stage 1:=================================================>       (26 + 4) / 30][Stage 1:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:38:40 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[Stage 3:>                                                         (0 + 4) / 30][Stage 3:=======>                                                  (4 + 4) / 30][Stage 3:===========>                                              (6 + 4) / 30][Stage 3:===============>                                          (8 + 4) / 30][Stage 3:===================>                                     (10 + 4) / 30][Stage 3:======================>                                  (12 + 4) / 30][Stage 3:========================>                                (13 + 4) / 30][Stage 3:============================>                            (15 + 4) / 30][Stage 3:==============================>                          (16 + 4) / 30][Stage 3:================================>                        (17 + 4) / 30][Stage 3:==================================>                      (18 + 4) / 30][Stage 3:======================================>                  (20 + 4) / 30][Stage 3:=======================================>                 (21 + 4) / 30][Stage 3:=========================================>               (22 + 4) / 30][Stage 3:=============================================>           (24 + 4) / 30][Stage 3:===============================================>         (25 + 4) / 30][Stage 3:=================================================>       (26 + 4) / 30][Stage 3:=====================================================>   (28 + 2) / 30][Stage 3:=======================================================> (29 + 1) / 30][Stage 4:>                                                         (0 + 4) / 30][Stage 4:=>                                                        (1 + 4) / 30][Stage 4:=====>                                                    (3 + 4) / 30][Stage 4:=======>                                                  (4 + 4) / 30][Stage 4:===========>                                              (6 + 4) / 30][Stage 4:=============>                                            (7 + 4) / 30][Stage 4:===============>                                          (8 + 4) / 30][Stage 4:=================>                                        (9 + 4) / 30][Stage 4:===================>                                     (10 + 4) / 30][Stage 4:====================>                                    (11 + 4) / 30][Stage 4:======================>                                  (12 + 4) / 30][Stage 4:========================>                                (13 + 4) / 30][Stage 4:==========================>                              (14 + 4) / 30][Stage 4:============================>                            (15 + 4) / 30][Stage 4:==============================>                          (16 + 4) / 30][Stage 4:================================>                        (17 + 4) / 30][Stage 4:==================================>                      (18 + 4) / 30][Stage 4:====================================>                    (19 + 4) / 30][Stage 4:======================================>                  (20 + 4) / 30][Stage 4:=========================================>               (22 + 4) / 30][Stage 4:===========================================>             (23 + 4) / 30][Stage 4:=============================================>           (24 + 4) / 30][Stage 4:===============================================>         (25 + 4) / 30][Stage 4:=================================================>       (26 + 4) / 30][Stage 4:===================================================>     (27 + 3) / 30][Stage 4:=======================================================> (29 + 1) / 30]                                                                                16/11/30 20:40:28 ERROR TransportResponseHandler: Still have 2 requests outstanding when connection from node-4/10.40.0.230:49042 is closed
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@654f3a44 rejected from java.util.concurrent.ThreadPoolExecutor@347a7a52[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 31]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1372)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:133)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark-project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:133)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$1.processBatch$1(Future.scala:643)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$1.apply$mcV$sp(Future.scala:658)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$1.apply(Future.scala:635)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$1.apply(Future.scala:635)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch.run(Future.scala:634)
	at scala.concurrent.Future$InternalCallbackExecutor$.scala$concurrent$Future$InternalCallbackExecutor$$unbatchedExecute(Future.scala:694)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:685)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:208)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:230)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:230)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:71)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:110)
	at org.apache.spark.network.client.TransportResponseHandler.channelUnregistered(TransportResponseHandler.java:124)
	at org.apache.spark.network.server.TransportChannelHandler.channelUnregistered(TransportChannelHandler.java:94)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:158)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:144)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelUnregistered(ChannelInboundHandlerAdapter.java:53)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:158)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:144)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelUnregistered(ChannelInboundHandlerAdapter.java:53)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:158)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:144)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelUnregistered(ChannelInboundHandlerAdapter.java:53)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:158)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:144)
	at io.netty.channel.DefaultChannelPipeline.fireChannelUnregistered(DefaultChannelPipeline.java:739)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:659)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:627)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:362)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@2816ba97 rejected from java.util.concurrent.ThreadPoolExecutor@347a7a52[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 31]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1372)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:133)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:324)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark-project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:133)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$1.processBatch$1(Future.scala:643)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$1.apply$mcV$sp(Future.scala:658)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$1.apply(Future.scala:635)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch$$anonfun$run$1.apply(Future.scala:635)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.Future$InternalCallbackExecutor$Batch.run(Future.scala:634)
	at scala.concurrent.Future$InternalCallbackExecutor$.scala$concurrent$Future$InternalCallbackExecutor$$unbatchedExecute(Future.scala:694)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:685)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:208)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:230)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2.apply(NettyRpcEnv.scala:230)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:71)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:110)
	at org.apache.spark.network.client.TransportResponseHandler.channelUnregistered(TransportResponseHandler.java:124)
	at org.apache.spark.network.server.TransportChannelHandler.channelUnregistered(TransportChannelHandler.java:94)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:158)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:144)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelUnregistered(ChannelInboundHandlerAdapter.java:53)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:158)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:144)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelUnregistered(ChannelInboundHandlerAdapter.java:53)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:158)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:144)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelUnregistered(ChannelInboundHandlerAdapter.java:53)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:158)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelUnregistered(AbstractChannelHandlerContext.java:144)
	at io.netty.channel.DefaultChannelPipeline.fireChannelUnregistered(DefaultChannelPipeline.java:739)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:659)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:328)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:627)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:362)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)
16/11/30 20:40:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/11/30 20:40:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/11/30 20:40:28 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
perf_stat_metrics.sh: line 4: 146224 Terminated              ( bash perf_stat_sub.sh $perfMetric $Workerpid )
perf_stat_metrics.sh: line 16:   995 Terminated              ( bash perf_stat_sub.sh $perfMetric $Workerpid )
instructions:uk
cycles:uk
branches:uk
branch-misses:uk
L1-dcache-load-misses
L1-dcache-loads
L1-dcache-stores
L1-dcache-store-misses
dTLB-loads
dTLB-load-misses
dTLB-stores
dTLB-store-misses
LLC-loads
